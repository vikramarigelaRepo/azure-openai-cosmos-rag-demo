{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: openai in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.55.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: azure-core in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.32.0)\n",
      "Requirement already satisfied: azure-cosmos in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (4.9.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (5.6.0)\n",
      "Collecting psycopg2 (from -r requirements.txt (line 7))\n",
      "  Using cached psycopg2-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting azure-identity (from -r requirements.txt (line 8))\n",
      "  Downloading azure_identity-1.19.0-py3-none-any.whl.metadata (80 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from azure-core->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from azure-core->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (23.2.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.115.5)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.4.3 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (1.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.26.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (3.10.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (11.0.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.0.12)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.8.0)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.1.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.41.3)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.13.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio->-r requirements.txt (line 6)) (0.32.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio-client==1.4.3->gradio->-r requirements.txt (line 6)) (2024.10.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from gradio-client==1.4.3->gradio->-r requirements.txt (line 6)) (12.0)\n",
      "Collecting cryptography>=2.5 (from azure-identity->-r requirements.txt (line 8))\n",
      "  Downloading cryptography-43.0.3-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity->-r requirements.txt (line 8))\n",
      "  Downloading msal-1.31.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity->-r requirements.txt (line 8))\n",
      "  Using cached msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 2)) (3.10)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.5->azure-identity->-r requirements.txt (line 8))\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio->-r requirements.txt (line 6)) (3.16.1)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r requirements.txt (line 8))\n",
      "  Downloading PyJWT-2.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting portalocker<3,>=1.4 (from msal-extensions>=1.2.0->azure-identity->-r requirements.txt (line 8))\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 6)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 6)) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core->-r requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core->-r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from tqdm>4->openai->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 6)) (13.9.4)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.5->azure-identity->-r requirements.txt (line 8))\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=1.2.0->azure-identity->-r requirements.txt (line 8)) (308)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 6)) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ut551dg\\documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 6)) (0.1.2)\n",
      "Using cached psycopg2-2.9.10-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "Downloading azure_identity-1.19.0-py3-none-any.whl (187 kB)\n",
      "Downloading cryptography-43.0.3-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.3/3.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading msal-1.31.1-py3-none-any.whl (113 kB)\n",
      "Using cached msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading PyJWT-2.10.0-py3-none-any.whl (23 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: PyJWT, pycparser, psycopg2, portalocker, cffi, cryptography, msal, msal-extensions, azure-identity\n",
      "Successfully installed PyJWT-2.10.0 azure-identity-1.19.0 cffi-1.17.1 cryptography-43.0.3 msal-1.31.1 msal-extensions-1.2.0 portalocker-2.10.1 psycopg2-2.9.10 pycparser-2.22\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UT551DG\\Documents\\ghrepos\\azure-openai-cosmos-rag-demo\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import urllib \n",
    "import gradio as gr\n",
    "\n",
    "from azure.core.exceptions import AzureError\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "#Cosmos DB imports\n",
    "from azure.cosmos import CosmosClient\n",
    "from azure.cosmos.aio import CosmosClient as CosmosAsyncClient\n",
    "from azure.cosmos import PartitionKey, exceptions\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \".env\" # following .env template change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "OPENAI_API_KEY = config['AZURE_OPENAI_KEY']\n",
    "OPENAI_API_ENDPOINT = config['AZURE_OPENAI_ENDPOINT']\n",
    "OPENAI_API_VERSION = config['AZURE_OPENAI_VERSION'] # at the time of authoring, the api version is 2024-02-01\n",
    "COMPLETIONS_MODEL_DEPLOYMENT_NAME = config['AZURE_OPENAI_COMPLETIONS_DEPLOYMENT']\n",
    "EMBEDDING_MODEL_DEPLOYMENT_NAME = config['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "COSMOSDB_NOSQL_ACCOUNT_KEY = config['COSMOSDB_KEY']\n",
    "COSMOSDB_NOSQL_ACCOUNT_ENDPOINT = config['COSMOSDB_URI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOAI_client = AzureOpenAI(api_key=OPENAI_API_KEY, azure_endpoint=OPENAI_API_ENDPOINT, api_version=OPENAI_API_VERSION,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text):\n",
    "    '''\n",
    "    Generate embeddings from string of text.\n",
    "    This will be used to vectorize data and user input for interactions with Azure OpenAI.\n",
    "    '''\n",
    "    response = AOAI_client.embeddings.create(input=text, model=EMBEDDING_MODEL_DEPLOYMENT_NAME)\n",
    "    embeddings =response.model_dump()\n",
    "    time.sleep(0.5) \n",
    "    return embeddings['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data file\n",
    "data =[]\n",
    "with open('text-sample.json', 'r') as d:\n",
    "    data = json.load(d)\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for title and content fields\n",
    "n = 0\n",
    "for item in data:\n",
    "    n+=1\n",
    "    item['id'] = str(n)\n",
    "    title = item['title']\n",
    "    content = item['content']\n",
    "    title_embeddings = generate_embeddings(title)\n",
    "    content_embeddings = generate_embeddings(content)\n",
    "    item['titleVector'] = title_embeddings\n",
    "    item['contentVector'] = content_embeddings\n",
    "    item['@search.action'] = 'upload'\n",
    "    print(\"Creating embeddings for item:\", n, \"/\" ,len(data), end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save embeddings to sample_text_w_embeddings.json file\n",
    "with open(\"text-sample_w_embeddings.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos_client = CosmosClient(url=COSMOSDB_NOSQL_ACCOUNT_ENDPOINT, credential=COSMOSDB_NOSQL_ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create database\n",
    "DATABASE_NAME = \"vector-nosql-db\"\n",
    "db= cosmos_client.create_database_if_not_exists(\n",
    "    id=DATABASE_NAME\n",
    ")\n",
    "properties = db.read()\n",
    "print(json.dumps(properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\":\"/titleVector\",\n",
    "            \"dataType\":\"float32\",\n",
    "            \"distanceFunction\":\"dotproduct\",\n",
    "            \"dimensions\":1536\n",
    "        },\n",
    "        {\n",
    "            \"path\":\"/contentVector\",\n",
    "            \"dataType\":\"float32\",\n",
    "            \"distanceFunction\":\"cosine\",\n",
    "            \"dimensions\":1536\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_policy = {\n",
    "    \"includedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"excludedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/\\\"_etag\\\"/?\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/titleVector/*\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/contentVector/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorIndexes\": [\n",
    "        {\"path\": \"/titleVector\",\n",
    "         \"type\": \"quantizedFlat\"\n",
    "        },\n",
    "        {\"path\": \"/contentVector\",\n",
    "         \"type\": \"quantizedFlat\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER_NAME = \"vector-nosql-cont\"\n",
    "CACHE_CONTAINER_NAME = \"vector-nosql-cache\"\n",
    "\n",
    "\n",
    "try:    \n",
    "    container = db.create_container_if_not_exists(\n",
    "                    id=CONTAINER_NAME,\n",
    "                    partition_key=PartitionKey(path='/id', kind='Hash'),\n",
    "                    indexing_policy=indexing_policy,\n",
    "                    vector_embedding_policy=vector_embedding_policy)\n",
    "\n",
    "    print('Container with id \\'{0}\\' created'.format(id))\n",
    "\n",
    "except exceptions.CosmosResourceExistsError:\n",
    "    print('A container with id \\'{0}\\' already exists'.format(id))\n",
    "\n",
    "\n",
    "# Create the cache collection with vector index\n",
    "try:\n",
    "    cache_container = db.create_container_if_not_exists(id=CACHE_CONTAINER_NAME, \n",
    "                                                  partition_key=PartitionKey(path='/id'), \n",
    "                                                  indexing_policy=indexing_policy,\n",
    "                                                  vector_embedding_policy=vector_embedding_policy)\n",
    "    print('Container with id \\'{0}\\' created'.format(cache_container.id)) \n",
    "\n",
    "except exceptions.CosmosHttpResponseError: \n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER_NAME = \"vector-nosql-cont\"\n",
    "CACHE_CONTAINER_NAME = \"vector-nosql-cache\"\n",
    "\n",
    "container = db.get_container_client(CONTAINER_NAME)\n",
    "cache_container = db.get_container_client(CACHE_CONTAINER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text-sample_w_embeddings.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "container_client = db.get_container_client(CONTAINER_NAME)\n",
    "\n",
    "for item in data:\n",
    "  print(\"writing item\",item['id'])\n",
    "  container_client.upsert_item(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_history(container, completions=3):\n",
    "    results = container.query_items(\n",
    "        query= '''\n",
    "        SELECT TOP @completions *\n",
    "        FROM c\n",
    "        ORDER BY c._ts DESC\n",
    "        ''',\n",
    "        parameters=[\n",
    "            {\"name\": \"@completions\", \"value\": completions},\n",
    "        ],enable_cross_partition_query=True)\n",
    "    results = list(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the services for running ML models?\"\n",
    "results = vector_search(query)\n",
    "for result in results: \n",
    "  #print(result)\n",
    "    print(f\"Similarity Score: {result['SimilarityScore']}\")\n",
    "    print(f\"patientId: {result['title']}\")  \n",
    "    print(f\"patientId: {result['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function helps to ground the model with prompts and system instructions.\n",
    "\n",
    "def generate_completion(vector_search_results, user_prompt, chat_history):\n",
    "    system_prompt = '''\n",
    "    You are an intelligent assistant for Microsoft Azure services.\n",
    "    You are designed to provide helpful answers to user questions about Azure services given the information about to be provided.\n",
    "        - Only answer questions related to the information provided below, provide at least 3 clear suggestions in a list format.\n",
    "        - Write two lines of whitespace between each answer in the list.\n",
    "        - If you're unsure of an answer, you can say \"\"I don't know\"\" or \"\"I'm not sure\"\" and recommend users search themselves.\"\n",
    "        - Only provide answers that have products that are part of Microsoft Azure and part of these following prompts.\n",
    "    '''\n",
    "\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "        #chat history\n",
    "    for chat in chat_history:\n",
    "        messages.append({'role': 'user', 'content': chat['prompt'] + \" \" + chat['completion']})\n",
    "\n",
    "    for item in vector_search_results:\n",
    "        messages.append({\"role\": \"system\", \"content\": item['content']})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "    response = AOAI_client.chat.completions.create(model=COMPLETIONS_MODEL_DEPLOYMENT_NAME, messages=messages,temperature=0)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "def cache_response(container, user_prompt, prompt_vectors, response):\n",
    "    # Create a dictionary representing the chat document\n",
    "    chat_document = {\n",
    "        'id':  str(uuid.uuid4()),  \n",
    "        'prompt': user_prompt,\n",
    "        'completion': response.choices[0].message.content,\n",
    "        'completionTokens': str(response.usage.completion_tokens),\n",
    "        'promptTokens': str(response.usage.prompt_tokens),\n",
    "        'totalTokens': str(response.usage.total_tokens),\n",
    "        'model': response.model,\n",
    "        'vector': prompt_vectors\n",
    "    }\n",
    "    # Insert the chat document into the Cosmos DB container\n",
    "    container.create_item(body=chat_document)\n",
    "    print(\"item inserted into cache.\", chat_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a vector search on the Cosmos DB container\n",
    "def get_cache(container, vectors, similarity_score=0.0, num_results=5):\n",
    "    # Execute the query\n",
    "    results = container.query_items(\n",
    "        query= '''\n",
    "        SELECT TOP @num_results *\n",
    "        FROM c\n",
    "        WHERE VectorDistance(c.vector,@embedding) > @similarity_score\n",
    "        ORDER BY VectorDistance(c.vector,@embedding)\n",
    "        ''',\n",
    "        parameters=[\n",
    "            {\"name\": \"@embedding\", \"value\": vectors},\n",
    "            {\"name\": \"@num_results\", \"value\": num_results},\n",
    "            {\"name\": \"@similarity_score\", \"value\": similarity_score},\n",
    "        ],\n",
    "        enable_cross_partition_query=True, populate_query_metrics=True)\n",
    "    results = list(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loop of user input and model output. You can now perform Q&A over the sample data!\n",
    "def chat_completion(cache_container,user_input):\n",
    "   # container = db.get_container_client(CONTAINER_NAME)\n",
    "    cache_container = db.get_container_client(CACHE_CONTAINER_NAME)\n",
    "    #while user_input.lower() != \"end\":\n",
    "    user_embeddings = generate_embeddings(user_input)\n",
    "\n",
    "   # Query the chat history cache first to see if this question has been asked before\n",
    "    cache_results = get_cache(container = cache_container, vectors = user_embeddings, similarity_score=0.99, num_results=1)\n",
    "    if len(cache_results) > 0:\n",
    "        print(\"Cached Result\\n\")\n",
    "        return cache_results[0]['completion'], True\n",
    "   \n",
    "    else: \n",
    "\n",
    "      print(\"New result\\n\")\n",
    "      search_results = vector_search(user_input)\n",
    "      #chat history\n",
    "      chat_history = get_chat_history(cache_container, 3)\n",
    "\n",
    "      completions_results = generate_completion(search_results, user_input,chat_history)\n",
    "      #completions_results = generate_completion(search_results, user_input)\n",
    "\n",
    "      print(\"\\n\")\n",
    "\n",
    "      print(\"Caching response \\n\")\n",
    "      #cache the response\n",
    "      cache_response(cache_container, user_input, user_embeddings, completions_results)\n",
    "\n",
    "      return completions_results.choices[0].message.content, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\n",
    "print(\"***search for azure services ***.\\n\")\n",
    "user_input = input(\"User prompt: \")\n",
    "print(chat_completion(cache_container,user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Azure Assistant\")\n",
    "    \n",
    "    msg = gr.Textbox(label=\"Ask me about Azure Services!\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def user(user_message, chat_history):\n",
    "        # Create a timer to measure the time it takes to complete the request\n",
    "        start_time = time.time()\n",
    "        # Get LLM completion\n",
    "        response_payload, cached = chat_completion(cache_container, user_message)\n",
    "        # Stop the timer\n",
    "        end_time = time.time()\n",
    "        elapsed_time = round((end_time - start_time) * 1000, 2)\n",
    "        #response = response_payload\n",
    "        print(response_payload)\n",
    "        # Append user message and response to chat history\n",
    "        details = f\"\\n (Time: {elapsed_time}ms)\"\n",
    "        if cached:\n",
    "         details += \" (Cached)\"\n",
    "        chat_history.append([user_message, response_payload + details])\n",
    "        \n",
    "        return gr.update(value=\"\"), chat_history\n",
    "    \n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False)\n",
    "\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "# Launch the Gradio interface\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
